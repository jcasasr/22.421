{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "        <img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\" , align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">22.421 · Anàlisi de xarxes socials</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Grau de Ciència de Dades Aplicada (<i>Applied Data Science</i>)</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Informàtica, Multimèdia i Telecomunicació</p>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\"></div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracció de dades: el cas de Twitter i la seva API\n",
    "\n",
    "En aquest material veurem un cas particular d'extracció de dades d'una xarxa social: Twitter.\n",
    "\n",
    "En primer lloc, necessitarem les claus de desenvolupador per poder accedir a l'API de Twitter. Si ja les heu sol·licitat, les podreu obtenir des del vostre compte. En cas contrari, visiteu https://developer.twitter.com/en/apply-for-access.html per obtenir informació i sol·licitar accés les claus.\n",
    "\n",
    "La clau d'API de Twitter està, en realitat, format per quatre claus. Quan tingueu compte de desenvolupador, només cal accedir al menú **Apps** > **Create an app** i crear una *app* nova. Dins dels seus detalls trobareu **Keys and tokens**. Aquí es poden crear i regenerar les claus.\n",
    "\n",
    "Introduïu les vostres claus API a la primera cel·la. Recordeu que no s'han de compartir per evitar l'ús fraudulent i també per evitar superar els límits de l'API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:31:09.791277Z",
     "start_time": "2019-10-15T08:31:09.789013Z"
    }
   },
   "outputs": [],
   "source": [
    "####input your credentials here\n",
    "consumer_key = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "consumer_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "access_token = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "access_token_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tot i que podríem fer crides directament a l'API, una de les millors maneres és aprofitar alguna llibreria addicional perquè gestioni alguns temes per nosaltres i que ens simplifiqui les coses. En aquest cas, farem servir `Tweepy` (http://docs.tweepy.org/en/v3.8.0/), encara que n'hi ha d'altres igualment vàlides com `Twython` (podeu fer servir la que preferiu, si coneixeu altres llibreries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:32:45.416090Z",
     "start_time": "2019-10-15T08:32:45.092509Z"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un exemple senzill (”hola món” de Tweepy) consisteix a descarregar els Tweets del nostre propi TL (*timeline*). Això inclou els comptes que seguiu. Si no en teniu cap, escriviu-ne un. Poseu un text genèric \"Hola món\", per exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:34:31.514919Z",
     "start_time": "2019-10-15T08:34:30.678690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparem l'autenticació\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Preparem el mòdul api de Tweepy (que és el que ens ajudarà a fer les \"preguntes\" a la API)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# I fem la primera crida: fixeu-vos que `api.home_timeline()` és una funció que retorna els tweets del nostre compte \n",
    "# timeline (de l'usuari de les claus)\n",
    "public_tweets = api.home_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:34:31.680947Z",
     "start_time": "2019-10-15T08:34:31.677992Z"
    }
   },
   "outputs": [],
   "source": [
    "# La crida retorna un conjunt de tweets que es poden iterar. Vegem els textos, per exemple.\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check\n",
    "\n",
    "Podeu comprovar com coincideixen amb el que veieu al client web de Twitter o la seva app mòbil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recórrer i treure informació dels Tweets\n",
    "\n",
    "Cada objecte que s'obté de `Tweepy` té diversos atributs. Abans hem vist que amb \".text\" obtenim el text del tweet i, si busqueu a la documentació, en veureu molts més. Però el que ens serà més útil aquí serà utilitzar directament el JSON (JSON és un format estructurat de dades) en brut, accessible a partir de \"._json\".\n",
    "\n",
    "Per exemple, imagineu que voleu veure els noms dels autors dels últims tweets del vostre TL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:37:48.647561Z",
     "start_time": "2019-10-15T08:37:48.643613Z"
    }
   },
   "outputs": [],
   "source": [
    "for tweet in public_tweets:\n",
    "    print(tweet._json['user']['screen_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixeu-vos que l'accés és com un diccionari, una forma que ja heu vist en el passat. Però... per què encara que el meu TL tingui centenars o milers de missatges només estic veient els darrers 20? Aquí hi ha una de les parts més rellevants de tot això.\n",
    "\n",
    "## Límits\n",
    "\n",
    "L'API de Twitter té límits, més laxos en alguns casos, més estrictes en altres. Teniu la referència a totes les funcions de l'API a https://developer.twitter.com/en/docs/api-reference-index, però per a l'explicació ens centrarem en dues: Search i Friends.\n",
    "\n",
    "A Search (https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets), trobareu els detalls dels paràmetres per fer les trucades, juntament amb un exemple i una resposta d'exemple. A això ens ajudarà Tweepy, però hauríeu de fixar-vos una mica més amunt, a la part de \"Resource information\". Hi ha un apartat que posa \"Rate Limited?\" (Yes), cosa que significa que té màxims de preguntes. I més avall, \"Requests/15-min window (app auth)\" (450). Això el que significa és, bàsicament, que cada 15 minuts només podeu fer 450 preguntes de cerca. Sembla molt però no ho és; cada \"pregunta\" retorna com a molt 100 tweets (o 15 si no especifiquem res), de manera que obtenir dades sobre un hashtag o paraula popular pot consumir fàcilment les 450 crides. A més, la part gratuïta només dóna informació de cerca dels darrers 7 dies, així que cal tenir-ho en compte.\n",
    "\n",
    "A Friends, que és una altra que podria ser interessant (per veure qui segueix un usuari concret), hi trobem un problema greu. Fixeu-vos que només permet 15! crides cada 15 minuts. És a dir, en una xarxa petita, de 1500 usuaris, estaríem unes 25 hores per treure tota la informació si no fallés res. La realitat és que, probablement, estiguem dia i mig o dos dies sencers. Tingueu-ho en compte si planegeu usar aquesta (interessant, això sí), relació.\n",
    "\n",
    "Normalment gestionaríem això des de Python. Faríem una trucada a l'API i ens tornaria un valor (https://developer.twitter.com/en/docs/basics/response-codes ). \"200\" és l'indicador que tot està bé, però si torna un altre codi és que hi ha un error. \"429\", per exemple, és \"Too many requests\", indicador d'haver excedit el límit. Això ho processaríem com una excepció i, si hi entrés, esperaríem 15 minuts abans de tornar a trucar (o un temps prudencial). La sort és que Tweepy ho pot fer per nosaltres així que, per a l'objectiu d'aquest tutorial, no cal preocupar-se en excés (més enllà de tenir-ho en compte com a limitació d'extracció).\n",
    "\n",
    "## Cerca\n",
    "\n",
    "Farem un exemple de cerca amb Tweepy, que no tan sols gestiona els temps d'espera sinó també les extraccions més grans que la mida màxima de cerca - usant un invent anomenat cursor. Funciona així:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:49:19.157811Z",
     "start_time": "2019-10-15T08:49:17.384087Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fem una cerca de Tweets amb la paraula #Barcelona o #Madrid\n",
    "\n",
    "# Es poden utilitzar operadors binaris (més detall a la documentació de la API)\n",
    "for tweet in tweepy.Cursor(api.search,q=(\"#Barcelona OR #Madrid\"),count=100,\n",
    "                           tweet_mode= 'extended').items(200):\n",
    "    print(tweet._json['full_text'])\n",
    "    if 'retweeted_status' in tweet._json:\n",
    "        print(\"Es un RT y su texto completo es: \" + tweet._json['retweeted_status']['full_text'])\n",
    "\n",
    "# Acabem de demanar els 200 tweets més recents, retornats en pàgines de 100 (que és el màxim)\n",
    "# Amb les paraules #Barcelona o #Madrid\n",
    "# tweet_mode = extended s'usa perquè des que Twitter va allargar els tweets (de 140 a 280 caràcters)\n",
    "# s'emmagatzema el tweet de 280 caràcters en un altre atribut; el \"text\" normal estaria truncat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T22:49:37.017188Z",
     "start_time": "2019-10-14T22:49:37.011516Z"
    }
   },
   "source": [
    "Fixeu-vos en les diferències entre camps i en l'accés dins dels RT. Podeu jugar amb això i investigar.\n",
    "\n",
    "## Problema: I l'emmagatzematge?\n",
    "\n",
    "Fins aquest punt, cada vegada que busquem un conjunt de tweets a les instruccions anteriors, aquests es renoven o desapareixen. Així que interessa fer-ne una extracció i conservar-la. Aquí hi ha dues estratègies bàsiques:\n",
    "\n",
    "- O bé es conserven els camps que siguin rellevants per a lexercici en un fitxer estructurat (per exemple, en un CSV que tingui per files els usuaris i les seves interaccions).\n",
    "\n",
    "- O bé es fa servir una base de dades per a l'emmagatzematge. Aquí es recomana utilitzar MongoDB, que a més té una llibreria molt senzilla per a Python anomenada `pymongo`.\n",
    "\n",
    "Totes dues opcions poden ser vàlides.\n",
    "\n",
    "L'opció més senzilla és un CSV i es pot fer de múltiples maneres al gust del consumidor. Aquí un exemple, encara que normalment guardaríem més camps (usuari al qual es fa RT en cas de ser-ho, a qui respon, etc.). Noteu que si feu servir un CSV cal contemplar tots els casos i preparar tokens o comodins per a camps buits (e.g. si un Tweet no és un RT, posar un \"*None*\" en aquest camp). Cada fila ha de contenir el mateix nombre dítems, és important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:51:13.076122Z",
     "start_time": "2019-10-15T08:51:11.358010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardem en un CSV fila per fila, ull que els caràcters separadors són importants\n",
    "import csv\n",
    "\n",
    "with open('tweet_list.csv', 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=';', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for tweet in tweepy.Cursor(api.search,q=(\"#Barcelona OR #Madrid\"),count=100,\n",
    "                           tweet_mode= 'extended').items(200):\n",
    "                retweet = False\n",
    "                if hasattr(tweet, 'retweeted_status'):\n",
    "                    retweet = True\n",
    "                writer.writerow([tweet._json['user']['id'], tweet._json['user']['screen_name'], tweet._json['full_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T08:51:19.812629Z",
     "start_time": "2019-10-15T08:51:17.615181Z"
    }
   },
   "outputs": [],
   "source": [
    "# I per una lectura ràpida i estructurada, fem servir pandas:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tweet_list.csv', header=None, sep=\";\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per MongoDB:\n",
    "\n",
    "- Instal·lació: https://docs.mongodb.com/manual/administration/install-community/\n",
    "- Inici: https://docs.mongodb.com/manual/tutorial/install-mongodb-on-windows/#run-mdb-edition-from-the-command-interpreter (cal iniciar el servei mongod cada vegada que es vulgui utilitzar).\n",
    "- GUI (Compass): https://www.mongodb.com/download-center/compass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple MongoDB\n",
    "\n",
    "# Importem PyMongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Creem una connexió amb la BBDD\n",
    "client = MongoClient()\n",
    "           \n",
    "# Utilitzem una base de dades anomenada test\n",
    "db = client.test\n",
    "\n",
    "# I cada Tweet s'emmagatzema en una col·lecció anomenada \"tweets\"\n",
    "for tweet in tweepy.Cursor(api.search,q=(\"#Barcelona OR #Madrid\"),count=100,\n",
    "                           tweet_mode= 'extended').items(200):\n",
    "    db.tweets.insert_one(tweet._json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperació de MongoDB\n",
    "\n",
    "Ara ja podríem treballar amb les dades que s'han recollit a la BBDD d'una manera ben directa: la nostra BBDD passaria a ser la font de tweets. Fixeu-vos en el seu ús base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for result in db.tweets.find():\n",
    "            uid = result['user']['screen_name']\n",
    "            G.add_node(uid) # si ja existeix, s'omet automàticament\n",
    "            \n",
    "            # Hi ha més casuístiques, però per exemple, amb el retweeted_status (és a dir, un usuari ha fet RT a un altre)\n",
    "            if 'retweeted_status' in result:\n",
    "                if G.has_edge(uid, result['retweeted_status']['user']['screen_name']):\n",
    "                    G[uid][result['retweeted_status']['user']['screen_name']]['weight'] += 1.0\n",
    "                else:\n",
    "                    G.add_edge(uid, result['retweeted_status']['user']['screen_name'], weight = 1.0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podeu fer servir Compass per veure el contingut de la BBDD.\n",
    "\n",
    "# *Streaming*\n",
    "\n",
    "Moltes vegades, però, a les plataformes en línia ens interessa \"consumir\" informació al moment. Si abans hem vist la cerca, ara veurem el streaming en temps real.\n",
    "\n",
    "https://developer.twitter.com/en/docs/tweets/filter-realtime/overview\n",
    "\n",
    "Una consideració important: si feu servir *streaming* per a una investigació té un problema de base. Twitter afirma que només ens proporciona un mostreig de, aproximadament, l'1% dels tweets que circulen en qualsevol moment i ho fa segons el seu algorisme de rellevància. Així que el que obteniu és un filtre sobre una mostra filtrada per la rellevància segons Twitter. Això podria ser bo però la realitat és que, com veureu, de vegades obtenim molt *spam* tuitero.\n",
    "\n",
    "Com preparem un Stream amb Tweepy? Conceptualment és diferent del que hem vist fins ara, perquè en realitat el que farem és preparar un fil que deixarà el nostre programa \"escoltant\" del Stream de Twitter i cada vegada que arribi un tweet que coincideixi amb el nostre filtre saltarà a una rutina per tractar-lo (per exemple, per emmagatzemar-lo o escriure'l) i continuarà escoltant. Cal mantenir aquesta rutina al mínim per evitar que interfereixi amb el següent *tweet* (encara que es posi a una cua, si s'omple el *pipeline*, la connexió es trenca automàticament)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:02:01.841583Z",
     "start_time": "2019-10-15T09:01:32.951809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Per treballar amb json's\n",
    "import json\n",
    "\n",
    "# Llista amb les paraules\n",
    "WORDS = ['#barcelona', '#madrid']\n",
    "\n",
    "# Les claus\n",
    "consumer_key = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "consumer_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "access_token = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "access_token_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "\n",
    "# Crear la classe que realitzarà l'escolta\n",
    "class StreamListener(tweepy.StreamListener):    \n",
    "    # Aquesta és la classe que fa servir tweepy per accedir a la API de Streaming. \n",
    "\n",
    "    def on_connect(self):\n",
    "        # Per connectar a la Streaming API\n",
    "        print(\"You are now connected to the streaming API.\")\n",
    " \n",
    "    def on_error(self, status_code):\n",
    "        # Si hi ha error no desconecta, però mostra l'error\n",
    "        print('An Error has occured: ' + repr(status_code))\n",
    "        return False\n",
    " \n",
    "    def on_data(self, data):\n",
    "        # Tractament al rebre \"data\" (un tweet)\n",
    "        # Podríem, per exemple, connectar al mongoDB i desar el tweet\n",
    "        try:\n",
    "            \n",
    "            # Codi d'exemple, però recordeu que els imports els hem indicat anteriorment\n",
    "            '''client = MongoClient()\n",
    "            db = client.testserver\n",
    "            datajson = json.loads(data)\n",
    "            db.tweets.insert_one(datajson)'''\n",
    "            \n",
    "            # Codificació de JSON a Python\n",
    "            datajson = json.loads(data)\n",
    "            \n",
    "            # Obtenim el text\n",
    "            text = datajson['text']\n",
    "            fecha = datajson['created_at']\n",
    "\n",
    "            # I printem un missatge indicant que s'ha capturat un Tweet            \n",
    "            print(\"Tweet capturat a les \"  + str(fecha) + \" amb el text \" + str(text))\n",
    "           \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Parem l'escolta (listener)\n",
    "# Cal posar el 'wait_on_rate_limit=True' per gestionar les limitacions de la API de Twitter.\n",
    "listener = StreamListener(api=tweepy.API(wait_on_rate_limit=True)) \n",
    "streamer = tweepy.Stream(auth=auth, listener=listener)\n",
    "\n",
    "# Imprimir el que estem buscant\n",
    "print(\"Tracking: \" + str(WORDS))\n",
    "streamer.filter(track=WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els streams no tenen \"fi\". Cal aturar-los manualment i reiniciar el codi sencer si volem tornar a activar-lo i no tenir problemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
